getwd()
library(dplyr)
train.labeled <- read.delim("labeledTrainData.tsv", header = T, quote = ’’, stringsAsFactors = F)
train.labeled <- read.delim("labeledTrainData.tsv", header = T, quote = "", stringsAsFactors = F)
library(tm)
library(SnowballC)
library(e1071)
library(caret)
library(randomForest)
data_train <- read.delim(unz("labeledTrainData.tsv.zip",
"labeledTrainData.tsv"),
header = TRUE,
sep = "\t",
quote = "",
as.is=TRUE)
str(data_train)
head(data_train)
r1_length <- nchar(as.character(data_train[1,3]))
r1 <- data_train[1,3]
paste(substr(r1,1,700),"...")
train_corpus = Corpus(VectorSource(data_train$review))
train_corpus = tm_map(train_corpus, tolower)
train_corpus = tm_map(train_corpus, PlainTextDocument)
train_corpus[[1]]
train_corpus = tm_map(train_corpus, removePunctuation)
train_corpus = tm_map(train_corpus, removeWords, c("movie", stopwords("english")))
train_corpus[[1]]
train_corpus = tm_map(train_corpus, stemDocument)
train_corpus[[1]]
frequencies = DocumentTermMatrix(train_corpus)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
frequencies
sparse = removeSparseTerms(frequencies, 0.995)
sparse
sparse = removeSparseTerms(frequencies, 0.99)
sparse
sparse = removeSparseTerms(frequencies, 0.9)
sparse
findFreqTerms(train_bag, 5000, Inf)
findFreqTerms(sparse, 5000, Inf)
reviewSparse = as.data.frame(as.matrix(sparse))
colnames(reviewSparse) = make.names(colnames(reviewSparse))
reviewSparse$sentiment <- data_train$sentiment
names(reviewSparse)
vocab <- names(reviewSparse)[-147]
rm(train_corpus)
forest <- train(as.factor(sentiment) ~., data=reviewSparse,
method="rf",
trControl=trainControl(method="cv",number=5),
prox=TRUE,
ntree=100,
do.trace=10,
allowParallel=TRUE)
forest <- train(as.factor(sentiment) ~., data=reviewSparse,
method="rf",
trControl=trainControl(method="cv",number=5),
prox=TRUE,
ntree=100,
do.trace=10,
metric = "ROC",
allowParallel=TRUE)
forest <- train(as.factor(sentiment) ~., data=reviewSparse,
method="rf",
trControl=trainControl(method="cv",number=5, classProbs = TRUE),
prox=TRUE,
ntree=100,
do.trace=10,
metric = "ROC",
allowParallel=TRUE)
forest <- train(factor(sentiment) ~., data=reviewSparse,
method="rf",
trControl=trainControl(method="cv",number=5, classProbs = TRUE),
prox=TRUE,
ntree=100,
do.trace=10,
metric = "ROC",
allowParallel=TRUE)
head(factor(data_train$sentiment))
require(plyr)
require(dplyr)
data_train$sentiment %<>% revalue(., c("0"="neg", "1" = "pos"))
require(magrittr)
data_train$sentiment %<>% revalue(., c("0"="neg", "1" = "pos"))
data_train$sentiment %<>% as.factor(.)
data_train$sentiment %<>% revalue(., c("0"="neg", "1" = "pos"))
forest <- train(sentiment ~., data=reviewSparse,
method="rf",
trControl=trainControl(method="cv",number=5, classProbs = TRUE),
prox=TRUE,
ntree=100,
do.trace=10,
metric = "ROC",
allowParallel=TRUE)
cv_ctrl <- trainControl(method="cv", number=5, summaryFunction = twoClassSummary, classProbs = TRUE)
forest <- train(sentiment ~., data=reviewSparse,
method="rf",
trControl=cv_ctrl,
prox=TRUE,
ntree=100,
do.trace=10,
metric = "ROC",
allowParallel=TRUE)
reviewSparse$sentiment <- data_train$sentiment
forest <- train(sentiment ~., data=reviewSparse,
method="rf",
trControl=trainControl(method="cv",number=5, classProbs = TRUE),
prox=TRUE,
ntree=100,
do.trace=10,
metric = "ROC",
allowParallel=TRUE)
warnings()
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100)
head(row.names(reviewSparse)
)
row.names(reviewSparse) <- NULL
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100)
forest <- train(sentiment ~., data=reviewSparse[sample(nrow(reviewSparse), size = 1000),],
method="rf",
trControl=trainControl(method = "repeatedcv", repeats = 10,, classProbs = TRUE),
prox=TRUE,
ntree=100,
do.trace=10,
metric = "ROC",
allowParallel=TRUE)
forest <- train(sentiment ~., data=reviewSparse[sample(nrow(reviewSparse), size = 1000),],
method="rf",
trControl=trainControl(method="cv",number=5, classProbs = TRUE),
prox=TRUE,
ntree=100,
do.trace=10,
metric = "ROC",
allowParallel=TRUE)
cv_ctrl <- trainControl(method="cv", number=5, summaryFunction = twoClassSummary, classProbs = TRUE)
forest <- train(sentiment ~., data=reviewSparse[sample(nrow(reviewSparse), size = 1000),],
method="rf",
trControl=cv_ctrl,
prox=TRUE,
ntree=100,
do.trace=10,
metric = "ROC",
allowParallel=TRUE)
forest
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100, mtry = 74)
testing <- read.delim(unz("testData.tsv.zip",
"testData.tsv"),
header = TRUE,
sep = "\t",
quote = "")
testing <- read.delim(unz("testData.tsv.zip",
"testData.tsv"),
header = TRUE,
sep = "\t",
quote = "", stringsAsFactors = F)
test_corpus = Corpus(VectorSource(testing$review))
test_corpus = tm_map(test_corpus, tolower)
test_corpus = tm_map(test_corpus, PlainTextDocument)
test_corpus = tm_map(test_corpus, removePunctuation)
test_corpus = tm_map(test_corpus, removeWords, c("movie", stopwords("english")))
test_corpus = tm_map(test_corpus, stemDocument)
test_frequencies = DocumentTermMatrix(test_corpus,control=list(dictionary = vocab))
reviewSparse_test = as.data.frame(as.matrix(test_frequencies))
sentiment <- predict(model_rf, newdata = reviewSparse_test)
sentiment <- rep(0, 25000)
sentiment <- predict(model_rf, newdata = reviewSparse_test)
test_df <- cbind(testing[,1], sentiment, reviewSparse_test)
row.names(reviewSparse_test)
row.names(reviewSparse_test) <- NULL
sentiment <- predict(model_rf, newdata = reviewSparse_test)
head(sentiment)
sentiment
reviewSparse$sentiment
sentiment <- rep(0, 25000)
test_df <- cbind(testing[,1], sentiment, reviewSparse_test)
names(test_df)[1] <- "id"
test_df[,2] <- predict(model_rf, newdata = test_df)
write.csv(test_df[,1:2], file="Submission_rf_tf.csv",
quote=FALSE,
row.names=FALSE)
test_df$sentiment %<>% revalue(., c("neg"="0", "pos" = "1"))
write.csv(test_df[,1:2], file="Submission_rf_tf.csv",
quote=FALSE,
row.names=FALSE)
data_train <- read.delim(unz("labeledTrainData.tsv.zip",
"labeledTrainData.tsv"),
header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
data_train[1,3]
paste(substr(data_train[1,3],1,700),"...")
library(magrittr)
library(tm)
train_corpus <- data_train$review %>% Corpus(VectorSource(.)) %>%
tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument)
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>%
tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument)
frequencies = DocumentTermMatrix(train_corpus)
frequencies
require(plyr)
require(dplyr)
sparse = removeSparseTerms(frequencies, 0.9)
sparse
reviewSparse = as.data.frame(as.matrix(sparse))
vocab <- names(reviewSparse)
reviewSparse$sentiment <- data_train$sentiment %>% as.factor(.) %>%
revalue(., c("0"="neg", "1" = "pos"))
reviewSparse$sentiment
library(randomForest)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 400)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 300)
names(reviewSparse)
row.names(reviewSparse)
row.names(reviewSparse) <- NULL
row.names(reviewSparse)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 300, do.trace=T)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 200, do.trace=T)
library("doParallel")
cl <- makePSOCKcluster(2)
registerDoParallel(cl)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 200, do.trace=T)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100, do.trace=T)
model_rf$importance
model_rf$importanceSD
model_rf$localImportance
order(model_rf$importance)
data_test <- read.delim(unz("testData.tsv.zip",
"testData.tsv"),
header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
test_corpus <- data_test$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument)
test_frequencies = DocumentTermMatrix(test_corpus,control=list(dictionary = vocab))
reviewSparse_test = as.data.frame(as.matrix(test_frequencies))
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
row.names(reviewSparse_test) <- NULL
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
sentiment_test
sentiment_test %<>% revalue(., c("neg"="0", "pos" = "1"))
sentiment_test
pred_test <- cbind(data_test$id, sentiment_test)
names(pred_test)
colnames(pred_test) <- c("id", "sentiment")
names(pred_test)
colnames(pred_test)
write.csv(pred_test, file="Submission.csv",
quote=FALSE,
row.names=FALSE)
pred_test[,2]
sentiment_test
pred_test <- cbind(data_test$id, sentiment_test)
pred_test[,2]
sentiment_test
pred_test[,2]
str(pred_test)
pred_test <- as.data.frame(pred_test)
str(pred_test)
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
pred_test <- as.data.frame(cbind(data_test$id, sentiment_test))
colnames(pred_test) <- c("id", "sentiment")
str(pred_test)
pred_test$sentiment %<>% revalue(., c("neg"="0", "pos" = "1"))
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
sentiment_test
sentiment_test %<>% revalue(., c("neg"="0", "pos" = "1"))
sentiment_test
pred_test <- as.data.frame(cbind(data_test$id, sentiment_test))
str(pred_test)
pred_test$sentiment_test
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
pred_test <- as.data.frame(cbind(data_test$id, sentiment_test))
colnames(pred_test) <- c("id", "sentiment")
pred_test$sentiment %<>% revalue(., c("1"="0", "2" = "1"))
pred_test$sentiment
write.csv(pred_test, file="Submission.csv", quote=FALSE, row.names=FALSE)
frequencies
sparse <- removeSparseTerms(frequencies, 0.995)
sparse
sparse <- removeSparseTerms(frequencies, 0.999)
sparse
pc <- princomp(sparse, cor=TRUE, scores=TRUE)
pc <- princomp(sparse)
sparse <- removeSparseTerms(frequencies, 0.995)
pc <- princomp(sparse)
sparse <- removeSparseTerms(frequencies, 0.95)
pc <- princomp(sparse)
sparse
rm(model_rf)
rm(test_corpus)
pc <- princomp(sparse, scores = T)
rm(test_frequencies)
rm(train_corpus)
pc <- princomp(sparse, scores = T)
rm(reviewSparse)
rm(reviewSparse_test)
pc <- princomp(sparse, scores = T)
library(magrittr)
library(tm)
require(plyr)
require(dplyr)
sparse
pc <- princomp(sparse, scores = T)
variance <- pc$sdev^2/sum(pc$sdev^2)
cumvar <- cumsum(variance)
cumvar <- data.frame(PC = 1:252, CumVar = cumvar)
length(cumvar)
cumvar <- data.frame(PC = 1:length(cumvar), CumVar = cumvar)
library(ggplot2)
ggplot(data = cumvar, aes(x = PC, y = CumVar)) + geom_point()
variance <- data.frame(PC = 1:length(cumvar), Var = variance*100)
variance <- data.frame(PC = 1:length(variance), Var = variance*100)
ggplot(data = variance[1:10,], aes(x = factor(PC), y = Var)) + geom_bar(stat = "identity")
sum(variance$Var[1:70])
sum(variance$Var[1:200])
rm(list = ls())
library(magrittr)
library(tm)
require(plyr)
require(dplyr)
library(ggplot2)
library(randomForest)
data_train <- read.delim("labeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument)
rm(train_corpus)
freq_neg <- data_train %>% filter(sentiment == 0)$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
data_train %>% filter(sentiment == 0)$review
data_train %>% filter(sentiment == 0)
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq.df <- colSums(freq_neg)
freq.df <- data.frame(word = names(freq.df), freq = freq.df)
rownames(freq.df) <- NULL
head(freq.df)
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq.df <- colSums(freq_neg)
freq.df <- data.frame(word = names(freq.df), freq = freq.df)
rownames(freq.df) <- NULL
head(freq.df)
head(arrange(freq.df, desc(freq)))
freq_df_neg <- freq.df
rm(freq.df)
freq_pos <- data_train %>% filter(sentiment == 1) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq_df_pos <- colSums(freq_pos)
freq_df_pos <- data.frame(word = names(freq_df_pos), freq = freq_df_pos)
rownames(freq_df_pos) <- NULL
head(arrange(freq_df_pos, desc(freq)))
freq.all <- merge(freq_df_neg, freq_df_pos, by = ’word’, all = T)
freq.all <- merge(freq_df_neg, freq_df_pos, by = "word", all = T)
freq.all$freq.x[is.na(freq.all$freq.x)] <- 0
freq.all$freq.y[is.na(freq.all$freq.y)] <- 0
freq.all$diff <- abs(freq.all$freq.x - freq.all$freq.y)
head(arrange(freq.all, desc(diff)))
freq_all$diff_norm <- abs(freq_all$freq.x - freq_all$freq.y)/
(freq_all$freq.x +freq_all$freq.y + 300)
freq_all <- freq.all
rm(freq.all)
freq_all$diff_norm <- abs(freq_all$freq.x - freq_all$freq.y)/
(freq_all$freq.x +freq_all$freq.y + 300)
head(arrange(freq_all, desc(diff_norm)))
freq_word <- arrange(freq_all, desc(diff_norm)) %>% select(diff_norm)[1:1000]
freq_word <- arrange(freq_all, desc(diff_norm)) %>% select(diff_norm) %>% slice(1:1000)
freq_word
freq_word <- arrange(freq_all, desc(diff_norm)) %>% select(word) %>% slice(1:1000)
freq_word
freq_word <- arrange(freq_all, desc(diff_norm)) %>% select(word) %>% slice(1:500)
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument)
vocab <- as.character(freq_word)
class(freq_word)
vocab <- as.factor(freq_word)
vocab <- is.factor(freq_word)
str(freq_word)
vocab
vocab <- as.character(freq_word$word)
frequencies = DocumentTermMatrix(train_corpus,control=list(dictionary = vocab))
frequencies
reviewSparse = as.data.frame(as.matrix(frequencies))
reviewSparse$sentiment <- data_train$sentiment %>% as.factor(.) %>%
revalue(., c("0"="neg", "1" = "pos"))
row.names(reviewSparse) <- NULL
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100, do.trace = T)
data_test <- read.delim("testData.tsv", header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
test_corpus <- data_test$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument)
test_frequencies <-  DocumentTermMatrix(test_corpus,control=list(dictionary = vocab))
reviewSparse_test <-  as.data.frame(as.matrix(test_frequencies))
row.names(reviewSparse_test) <- NULL
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
rm(test_corpus)
rm(train_corpus)
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
pred_test <- as.data.frame(cbind(data_test$id, sentiment_test))
colnames(pred_test) <- c("id", "sentiment")
pred_test$sentiment %<>% revalue(., c("1"="0", "2" = "1"))
write.csv(pred_test, file="Submission.csv", quote=FALSE, row.names=FALSE)
