pc <- princomp(sparse)
sparse <- removeSparseTerms(frequencies, 0.95)
pc <- princomp(sparse)
sparse
rm(model_rf)
rm(test_corpus)
pc <- princomp(sparse, scores = T)
rm(test_frequencies)
rm(train_corpus)
pc <- princomp(sparse, scores = T)
rm(reviewSparse)
rm(reviewSparse_test)
pc <- princomp(sparse, scores = T)
library(magrittr)
library(tm)
require(plyr)
require(dplyr)
sparse
pc <- princomp(sparse, scores = T)
variance <- pc$sdev^2/sum(pc$sdev^2)
cumvar <- cumsum(variance)
cumvar <- data.frame(PC = 1:252, CumVar = cumvar)
length(cumvar)
cumvar <- data.frame(PC = 1:length(cumvar), CumVar = cumvar)
library(ggplot2)
ggplot(data = cumvar, aes(x = PC, y = CumVar)) + geom_point()
variance <- data.frame(PC = 1:length(cumvar), Var = variance*100)
variance <- data.frame(PC = 1:length(variance), Var = variance*100)
ggplot(data = variance[1:10,], aes(x = factor(PC), y = Var)) + geom_bar(stat = "identity")
sum(variance$Var[1:70])
sum(variance$Var[1:200])
rm(list = ls())
library(magrittr)
library(tm)
require(plyr)
require(dplyr)
library(ggplot2)
library(randomForest)
data_train <- read.delim("labeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument)
rm(train_corpus)
freq_neg <- data_train %>% filter(sentiment == 0)$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
data_train %>% filter(sentiment == 0)$review
data_train %>% filter(sentiment == 0)
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq.df <- colSums(freq_neg)
freq.df <- data.frame(word = names(freq.df), freq = freq.df)
rownames(freq.df) <- NULL
head(freq.df)
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq.df <- colSums(freq_neg)
freq.df <- data.frame(word = names(freq.df), freq = freq.df)
rownames(freq.df) <- NULL
head(freq.df)
head(arrange(freq.df, desc(freq)))
freq_df_neg <- freq.df
rm(freq.df)
freq_pos <- data_train %>% filter(sentiment == 1) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq_df_pos <- colSums(freq_pos)
freq_df_pos <- data.frame(word = names(freq_df_pos), freq = freq_df_pos)
rownames(freq_df_pos) <- NULL
head(arrange(freq_df_pos, desc(freq)))
freq.all <- merge(freq_df_neg, freq_df_pos, by = ’word’, all = T)
freq.all <- merge(freq_df_neg, freq_df_pos, by = "word", all = T)
freq.all$freq.x[is.na(freq.all$freq.x)] <- 0
freq.all$freq.y[is.na(freq.all$freq.y)] <- 0
freq.all$diff <- abs(freq.all$freq.x - freq.all$freq.y)
head(arrange(freq.all, desc(diff)))
freq_all$diff_norm <- abs(freq_all$freq.x - freq_all$freq.y)/
(freq_all$freq.x +freq_all$freq.y + 300)
freq_all <- freq.all
rm(freq.all)
freq_all$diff_norm <- abs(freq_all$freq.x - freq_all$freq.y)/
(freq_all$freq.x +freq_all$freq.y + 300)
head(arrange(freq_all, desc(diff_norm)))
freq_word <- arrange(freq_all, desc(diff_norm)) %>% select(diff_norm)[1:1000]
freq_word <- arrange(freq_all, desc(diff_norm)) %>% select(diff_norm) %>% slice(1:1000)
freq_word
freq_word <- arrange(freq_all, desc(diff_norm)) %>% select(word) %>% slice(1:1000)
freq_word
freq_word <- arrange(freq_all, desc(diff_norm)) %>% select(word) %>% slice(1:500)
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument)
vocab <- as.character(freq_word)
class(freq_word)
vocab <- as.factor(freq_word)
vocab <- is.factor(freq_word)
str(freq_word)
vocab
vocab <- as.character(freq_word$word)
frequencies = DocumentTermMatrix(train_corpus,control=list(dictionary = vocab))
frequencies
reviewSparse = as.data.frame(as.matrix(frequencies))
reviewSparse$sentiment <- data_train$sentiment %>% as.factor(.) %>%
revalue(., c("0"="neg", "1" = "pos"))
row.names(reviewSparse) <- NULL
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100, do.trace = T)
data_test <- read.delim("testData.tsv", header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
test_corpus <- data_test$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c("movie", stopwords("english"))) %>%
tm_map(., stemDocument)
test_frequencies <-  DocumentTermMatrix(test_corpus,control=list(dictionary = vocab))
reviewSparse_test <-  as.data.frame(as.matrix(test_frequencies))
row.names(reviewSparse_test) <- NULL
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
rm(test_corpus)
rm(train_corpus)
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
pred_test <- as.data.frame(cbind(data_test$id, sentiment_test))
colnames(pred_test) <- c("id", "sentiment")
pred_test$sentiment %<>% revalue(., c("1"="0", "2" = "1"))
write.csv(pred_test, file="Submission.csv", quote=FALSE, row.names=FALSE)
rm(list= ls())
library(magrittr)
library(tm)
require(plyr)
require(dplyr)
library(ggplot2)
library(randomForest)
data_train <- read.delim("labeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
data_train_un <- read.delim("unlabeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
train_review <- rbind(data_train$review, data_train_un$review)
dib(train_review)
dim(train_review)
rownames(train_review) <- NULL
dim(train_review)
train_review[,1]
train_review <- c(data_train$review, data_train_un$review)
train_corpus <- train_review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
train_corpus <- tm_map(train_corpus, removeNumbers)
dtm <- DocumentTermMatrix(train_corpus,
control = list(weighting = function(x) weightTfIdf(x, normalize = F)))
dtm <- as.matrix(dtm)
dtm2 <- removeSparseTerms(dtm, 0.99)
dtm <- as.matrix(dtm2)
dtm
dtm2
frequency <- colSums(as.matrix(dtm2))
library("slam", lib.loc="C:/Program Files/R/R-3.2.2/library")
frequency <- rollup(dtm2, 2, FUN = sum)
frequency
dtm2 <- removeSparseTerms(dtm, 0.98)
dtm_mat <- as.matrix(dtm2)
dtm2
rm(list = ls())
data_train <- read.delim("labeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>% tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
dtm <- DocumentTermMatrix(train_corpus,
control = list(weighting = function(x) weightTfIdf(x, normalize = F)))
dtm2 <- as.matrix(dtm)
dtm
dtm2 <- removeSparseTerms(dtm, 0.99)
dtm2
dtm3 <- as.matrix(dtm)
tdm <- TermDocumentMatrix(train_corpus,
control = list(weighting = function(x) weightTfIdf(x, normalize = F)))
dtm2
tdm2 <- removeSparseTerms(dtm, 0.99)
tdm2 <- removeSparseTerms(tdm, 0.99)
tdm2
tdm
tdm2 <- removeSparseTerms(tdm, 0.999)
freq <- rollup(tdm2, 2,FUN = sum)
freq
freq <- as.matrix(freq)
freq
freq <- rollup(dtm, 1,FUN = sum)
freq
freq <- as.matrix(freq)
freq
freq <- rollup(tdm, 2,FUN = sum)
freq
freq <- as.matrix(freq)
freq
rm(list = ls())
library(magrittr)
library(tm)
require(plyr)
require(dplyr)
library(ggplot2)
library(randomForest)
data_train <- read.delim("labeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
data_train_un <- read.delim("unlabeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
train_review <- c(data_train$review, data_train_un$review)
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>% tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
tdm <- TermDocumentMatrix(train_corpus,
control = list(weighting = function(x) weightTfIdf(x, normalize = F)))
freq <- rollup(tdm, 2,FUN = sum)
library(slam)
freq <- rollup(tdm, 2,FUN = sum)
freq
freq <- as.matrix(freq)
freq
dim(freq)
names(freq)
row.names(freq)
dim(freq)
freq_df <- data.frame(word = row.names(freq), freq = freq)
head(freq_df)
row.names(freq_df) <- NULL
head(freq_df)
freq_df <- data.frame(word = row.names(freq), tfidf = freq)
row.names(freq_df) <- NULL
head(freq_df)
names(freq_df)
names(freq_df) <- c("word", "tf_idf")
names(freq_df)
names(freq_df)
head(freq_df)
head(arrange(freq_df, desc(tf_idf)))
head(arrange(freq_df, desc(tf_idf)),20)
rm(list = ls())
data_train <- read.delim("labeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq_df_neg <- colSums(freq_neg)
freq_df_neg <- data.frame(word = names(freq_df_neg), freq = freq_df_neg)
rownames(freq_df_neg) <- NULL
head(arrange(freq_df_neg, desc(freq)))
freq_pos <- data_train %>% filter(sentiment == 1) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument) %>% DocumentTermMatrix(.) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq_df_pos <- colSums(freq_pos)
freq_df_pos <- data.frame(word = names(freq_df_pos), freq = freq_df_pos)
rownames(freq_df_pos) <- NULL
head(arrange(freq_df_pos, desc(freq)))
freq_all <- merge(freq_df_neg, freq_df_pos, by = "word", all = T)
freq_all$freq.x[is.na(freq_all$freq.x)] <- 0
freq_all$freq.y[is.na(freq_all$freq.y)] <- 0
freq_all$diff <- abs(freq_all$freq.x - freq_all$freq.y)
head(arrange(freq_all, desc(diff)))
freq_all$diff_norm <- abs(freq_all$freq.x - freq_all$freq.y)/
(freq_all$freq.x +freq_all$freq.y + 300)
head(arrange(freq_all, desc(diff_norm)))
freq_word <- arrange(freq_all, desc(diff_norm)) %>% select(word) %>% slice(1:500)
vocab <- as.character(freq_word$word)
frequencies = DocumentTermMatrix(train_corpus,control=list(dictionary = vocab,
weighting = function(x) weightTfIdf(x, normalize = F) ))
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>% tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
frequencies = DocumentTermMatrix(train_corpus,control=list(dictionary = vocab,
weighting = function(x) weightTfIdf(x, normalize = F) ))
reviewSparse_train <-  as.data.frame(as.matrix(frequencies))
row.names(reviewSparse_train) <- NULL
head(reviewSparse_train)
names(reviewSparse_train)
reviewSparse_train$sentiment <- data_train$sentiment %>% as.factor(.) %>%
revalue(., c("0"="neg", "1" = "pos"))
model_rf <- randomForest(sentiment ~ ., data = reviewSparse_train, ntree = 100)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse_train, ntree = 100, do.trace = T)
data_test <- read.delim("testData.tsv", header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
test_corpus <- data_test$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
test_frequencies <-  DocumentTermMatrix(test_corpus,control=list(dictionary = vocab,
weighting = function(x) weightTfIdf(x, normalize = F)))
reviewSparse_test <-  as.data.frame(as.matrix(test_frequencies))
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
row.names(reviewSparse_test) <- NULL
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
pred_test <- as.data.frame(cbind(data_test$id, sentiment_test))
colnames(pred_test) <- c("id", "sentiment")
pred_test$sentiment %<>% revalue(., c("1"="0", "2" = "1"))
write.csv(pred_test, file="Submission.csv", quote=FALSE, row.names=FALSE)
rm(list = ls())
data_train <- read.delim("labeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>% tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
dtm <- DocumentTermMatrix(train_corpus,
control = list(weighting = function(x) weightTfIdf(x, normalize = F)))
dtm
sparse <- removeSparseTerms(frequencies, 0.9)
sparse <- removeSparseTerms(dtm, 0.9)
sparse
sparse <- removeSparseTerms(dtm, 0.93)
sparse
sparse <- removeSparseTerms(dtm, 0.94)
sparse
sparse <- removeSparseTerms(dtm, 0.95)
sparse
sparse <- removeSparseTerms(dtm, 0.96)
sparse
reviewSparse = as.data.frame(as.matrix(sparse))
vocab <- names(reviewSparse)
reviewSparse$sentiment <- data_train$sentiment %>% as.factor(.) %>%
revalue(., c("0"="neg", "1" = "pos"))
row.names(reviewSparse) <- NULL
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100, do.trace = T)
names(reviewSparse)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100, do.trace = T)
reviewSparse$sentiment
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100, do.trace = T)
reviewSparse$next
fix(reviewSparse)
select(reviewSparse, next)
select(reviewSparse, "next")
model_rf <- randomForest(sentiment ~ .-next, data = reviewSparse, ntree = 100, do.trace = T)
str(reviewSparse)
temp <- str(reviewSparse)
reviewSparse$abl
reviewSparse$new
reviewSparse$next
colnames(reviewSparse) = make.names(colnames(reviewSparse))
model_rf <- randomForest(sentiment ~ ., data = reviewSparse, ntree = 100, do.trace = T)
data_test <- read.delim("testData.tsv", header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
test_corpus <- data_test$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
test_frequencies <-  DocumentTermMatrix(test_corpus,control=list(dictionary = vocab,
weighting = function(x) weightTfIdf(x, normalize = F)))
reviewSparse_test <-  as.data.frame(as.matrix(test_frequencies))
row.names(reviewSparse_test) <- NULL
colnames(reviewSparse_test) = make.names(colnames(reviewSparse_test))
sentiment_test <- predict(model_rf, newdata = reviewSparse_test)
pred_test <- as.data.frame(cbind(data_test$id, sentiment_test))
colnames(pred_test) <- c("id", "sentiment")
pred_test$sentiment %<>% revalue(., c("1"="0", "2" = "1"))
write.csv(pred_test, file="Submission.csv", quote=FALSE, row.names=FALSE)
rm(list = ls())
data_train <- read.delim("labeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument) %>%
DocumentTermMatrix(.,
control=list(weighting = function(x) weightTfIdf(x, normalize = F)) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
)
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument) %>%
DocumentTermMatrix(.,
control=list(weighting = function(x) weightTfIdf(x, normalize = F))) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq_df_neg <- colSums(freq_neg)
freq_df_neg <- data.frame(word = names(freq_df_neg), freq = freq_df_neg)
rownames(freq_df_neg) <- NULL
head(arrange(freq_df_neg, desc(freq)))
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument) %>%
DocumentTermMatrix(.,
control=list(weighting = function(x) weightTfIdf(x, normalize = F))) %>%
removeSparseTerms(., 0.999) %>% as.matrix(.)
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
freq_neg <- freq_neg %>% DocumentTermMatrix(.,control=list(weighting = function(x) weightTfIdf(x, normalize = F)))
freq_neg
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
+         Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
+         tm_map(., removePunctuation) %>%
+         tm_map(., removeNumbers) %>%
+         tm_map(., removeWords, c(stopwords("english"))) %>%
+         tm_map(., stemDocument)
freq_neg <- data_train %>% filter(sentiment == 0) %>% select(review) %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>%
tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
freq_neg <- DocumentTermMatrix(freq_neg,control=list(weighting = function(x) weightTfIdf(x, normalize = F)))
freq_neg
rm(list = ls())
data_train <- read.delim("labeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
data_train_un <- read.delim("unlabeledTrainData.tsv",header = TRUE, sep = "\t",
quote = "", stringsAsFactors = F)
train_review <- c(data_train$review, data_train_un$review)
train_corpus <- train_review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>% tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
train_corpus
dtm <- DocumentTermMatrix(train_corpus,
control = list(weighting = function(x) weightTfIdf(x, normalize = F)))
dtm
freq <- rollup(dtm, 2,FUN = sum)
freq
freq <- as.matrix(freq)
freq
tdm <- TermDocumentMatrix(train_corpus,
control = list(weighting = function(x) weightTfIdf(x, normalize = F)))
freq <- rollup(tdm, 2,FUN = sum)
freq
freq <- as.matrix(freq)
freq_df <- data.frame(word = row.names(freq), tfidf = freq)
freq_df
freq_df$word
names(freq_df) <- c("word", "tf_idf")
row.names(freq_df) <- NULL
freq_df
freq_df %<>% arrange(desc(tf_idf))
head(freq_df)
vocab <- as.character(freq_df$word)[1:500]
train_corpus <- data_train$review %>% VectorSource(.)%>%
Corpus(.) %>% tm_map(., tolower) %>% tm_map(., PlainTextDocument) %>%
tm_map(., removePunctuation) %>% tm_map(., removeNumbers) %>%
tm_map(., removeWords, c(stopwords("english"))) %>%
tm_map(., stemDocument)
frequencies = DocumentTermMatrix(train_corpus,control=list(dictionary = vocab,
weighting = function(x) weightTfIdf(x, normalize = F) ))
reviewSparse_train <-  as.data.frame(as.matrix(frequencies))
frequencies
rm(data_train_un)
rm(tdm)
rm(dtm)
rm(train_review)
reviewSparse_train <-  as.data.frame(as.matrix(frequencies))
row.names(reviewSparse_train) <- NULL
reviewSparse_train$sentiment <- data_train$sentiment %>% as.factor(.) %>%
revalue(., c("0"="neg", "1" = "pos"))
model_rf <- randomForest(sentiment ~ ., data = reviewSparse_train, ntree = 100, do.trace = T)
reviewSparse_train <-  as.data.frame(as.matrix(frequencies))
colnames(reviewSparse_train) = make.names(colnames(reviewSparse_train))
row.names(reviewSparse_train) <- NULL
reviewSparse_train$sentiment <- data_train$sentiment %>% as.factor(.) %>%
revalue(., c("0"="neg", "1" = "pos"))
model_rf <- randomForest(sentiment ~ ., data = reviewSparse_train, ntree = 100, do.trace = T)
rm(data_train)
rm(train_corpus)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse_train, ntree = 100, do.trace = T)
rm(freq)
rm(freq_df)
model_rf <- randomForest(sentiment ~ ., data = reviewSparse_train, ntree = 100, do.trace = T)
